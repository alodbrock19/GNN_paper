{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d273a175",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.loader import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Imports from your custom modules ---\n",
    "# Ensure these files are in your python path\n",
    "from models import MST_GNN\n",
    "from dataset import InMemoryDynamicSP100  # Or DynamicSP100Stocks if using the on-the-fly version\n",
    "\n",
    "# --- 2. Hyperparameters & Setup ---\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# Data Params\n",
    "PAST_WINDOW = 25\n",
    "FUTURE_WINDOW = 1\n",
    "BATCH_SIZE = 32\n",
    "TRAIN_SPLIT = 0.8\n",
    "\n",
    "# Model Params\n",
    "INPUT_FEATURES = 9   # e.g., Open, Close, RSI, MACD...\n",
    "HIDDEN_SIZE = 64\n",
    "GRAPH_LAYERS = 2\n",
    "CROSS_LAYERS = 2\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 100\n",
    "\n",
    "# --- 3. Data Preparation ---\n",
    "\n",
    "# Define the graph builder function (if using the InMemory logic)\n",
    "def correlation_graph_builder(window_data):\n",
    "    # window_data: (Nodes, Time, Features)\n",
    "    # Extract close prices (assuming index 0)\n",
    "    prices = window_data[:, :, 0] # (Nodes, Time)\n",
    "    # Correlation matrix\n",
    "    corr = np.corrcoef(prices)\n",
    "    # Thresholding (Connect stocks with > 0.6 correlation)\n",
    "    adj = (corr > 0.6).astype(int)\n",
    "    # Remove self-loops here (the model adds them manually later)\n",
    "    np.fill_diagonal(adj, 0)\n",
    "    return adj\n",
    "\n",
    "# Load Dataset\n",
    "print(\"Loading Data...\")\n",
    "dataset = InMemoryDynamicSP100(\n",
    "    root=\"./data\", \n",
    "    past_window=PAST_WINDOW, \n",
    "    future_window=FUTURE_WINDOW,\n",
    "    adj_calculator=correlation_graph_builder\n",
    ")\n",
    "\n",
    "# Train/Test Split\n",
    "# We split by time (first 80% time steps for train, last 20% for test)\n",
    "num_train = int(len(dataset) * TRAIN_SPLIT)\n",
    "train_dataset = dataset[:num_train]\n",
    "test_dataset = dataset[num_train:]\n",
    "\n",
    "# Create Loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# --- 4. Model Initialization ---\n",
    "print(\"Initializing Model...\")\n",
    "model = MST_GNN(\n",
    "    in_features=INPUT_FEATURES,\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    num_graph_layers=GRAPH_LAYERS,\n",
    "    num_cross_layers=CROSS_LAYERS\n",
    ").to(DEVICE)\n",
    "\n",
    "# Optimizer & Loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.BCEWithLogitsLoss() # Combines Sigmoid + Binary Cross Entropy\n",
    "\n",
    "# --- 5. Training Functions ---\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        batch = batch.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 1. Forward Pass\n",
    "        # Output shape: (Batch_Size * Num_Nodes, 1)\n",
    "        logits = model(batch.x, batch.edge_index)\n",
    "        \n",
    "        # 2. Prepare Labels (Up/Down)\n",
    "        # batch.y contains continuous returns (e.g., 0.02, -0.01)\n",
    "        # We assume predictions are per-node. Check shape consistency.\n",
    "        # Usually batch.y shape is (Batch_Size * Num_Nodes)\n",
    "        labels = (batch.y > 0).float().view(-1, 1) \n",
    "        \n",
    "        # 3. Calculate Loss\n",
    "        loss = criterion(logits, labels)\n",
    "        \n",
    "        # 4. Backprop\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 5. Metrics\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Convert logits to probability > 0.5 for accuracy check\n",
    "        preds = (torch.sigmoid(logits) > 0.5).float()\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    accuracy = correct / total_samples\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            batch = batch.to(DEVICE)\n",
    "            \n",
    "            logits = model(batch.x, batch.edge_index)\n",
    "            labels = (batch.y > 0).float().view(-1, 1)\n",
    "            \n",
    "            loss = criterion(logits, labels)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            preds = (torch.sigmoid(logits) > 0.5).float()\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    accuracy = correct / total_samples\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "# --- 6. Main Execution Loop ---\n",
    "\n",
    "print(\"Starting Training...\")\n",
    "best_acc = 0.0\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train_loss, train_acc = train()\n",
    "    test_loss, test_acc = test()\n",
    "\n",
    "    print(f'Epoch {epoch:03d}: '\n",
    "          f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | '\n",
    "          f'Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}')\n",
    "    \n",
    "    # Save best model\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "        torch.save(model.state_dict(), 'best_mst_gnn_model.pth')\n",
    "        print(f\"  >>> New Best Model Saved! (Acc: {best_acc:.4f})\")\n",
    "\n",
    "print(\"Training Complete.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
