â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    PHASE 1: FOCAL LOSS IMPLEMENTATION                      â•‘
â•‘                          âœ… COMPLETE AND READY                             â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
 WHAT WAS CHANGED
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

FILE: /code/models/train.py
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âœ… ADDED: FocalLoss class (lines 14-57)
   - Implements Focal Loss from Lin et al. (2017)
   - Parameters: alpha (class weights), gamma (focusing parameter)
   - Reduces loss from easy examples, focuses on hard examples
   
âœ… CHANGED: Imports
   - Added: import torch
   - Added: from torch.nn import functional as F
   
Status: âœ… Non-breaking, fully backward compatible


FILE: /code/trend_classification.ipynb
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âœ… ADDED: Markdown cell (new Cell 1)
   - Explains Phase 1 strategy
   - Shows Focal Loss mathematical formula
   - Lists expected outcomes (35.56% â†’ 45-50%)

âœ… CHANGED: Training setup cell (Cell 11)
   - OLD: criterion = nn.CrossEntropyLoss()
   - NEW: criterion = FocalLoss(alpha=class_weights, gamma=2.0)
   - ADDED: class_weights = torch.tensor([0.3, 1.0, 0.3])
   - ADDED: from models.train import FocalLoss
   - ADDED: Detailed comments and logging

Status: âœ… Ready to run


â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
 WHAT DID NOT CHANGE (PRESERVED)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âœ… TGCN Architecture
   - Same model, same layers, same parameters
   - in_channels=13, hidden_size=16, layers_nb=2
   - use_gat=True

âœ… Data Loading
   - Same SP100Stocks dataset
   - Same preprocessing pipeline
   - All 100% of data used

âœ… Data Labels
   - Still 3-class (Down/Neutral/Up)
   - Still Â±0.55% threshold
   - Class distribution: Down 31.65%, Neutral 33.57%, Up 35.01%

âœ… Training Configuration
   - Optimizer: Adam (lr=0.005, weight_decay=1e-5)
   - Epochs: 100
   - Batch size: 32
   - Training loop: Same train() function

âœ… Evaluation
   - Same accuracy measurement
   - Same confusion matrix
   - Same classification report

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
 FOCAL LOSS EXPLAINED
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Problem:  Model defaults to majority class (Neutral at 33.57% of data)
          Results in only 35.56% accuracy vs 33.3% random baseline

Solution: Use Focal Loss to penalize easy examples and focus on hard ones
          
Formula:  FL(p_t) = -Î±_t * (1 - p_t)^Î³ * log(p_t)
          
Where:    p_t = probability of true class
          Î±_t = class weight (penalize majority)
          Î³ = focusing parameter (typically 2.0)

Config:   alpha = [0.3, 1.0, 0.3]  (penalize Neutral class more)
          gamma = 2.0                (focus on hard examples)

Effect:   â€¢ Reduces loss contribution from easy examples
          â€¢ Focuses training on misclassified samples
          â€¢ Forces model to learn Down/Up patterns better
          â€¢ Reduces model's bias toward Neutral class

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
 EXPECTED OUTCOMES
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Baseline (CrossEntropyLoss):  35.56% accuracy
Phase 1 Target (FocalLoss):   45-50% accuracy
Improvement Target:           10-14 percentage points

Success Criteria:
  â€¢ Accuracy > 42% (beats baseline + margin)
  â€¢ Confirms class imbalance is main bottleneck
  â€¢ Enables Phase 2: Multi-task learning

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
 HOW TO RUN PHASE 1
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1. Open: /code/trend_classification.ipynb
2. Run cells in order (Cell 1 â†’ Cell 12)
3. Monitor: Watch for accuracy improvement
4. Result: Compare final accuracy against 35.56% baseline
5. Decision: 
   - If > 42% â†’ Phase 1 validates approach, proceed to Phase 2 âœ…
   - If < 38% â†’ Class imbalance NOT main issue, investigate other factors
   - If 38-42% â†’ Partial success, investigate other bottlenecks

Estimated Runtime: ~1-2 hours on GPU

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
 DOCUMENTATION FILES CREATED
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1. /code/PHASE1_IMPLEMENTATION_SUMMARY.md
   â†’ Detailed implementation guide
   â†’ How to run, what to expect
   â†’ Troubleshooting guide

2. /code/PHASE1_CHECKLIST.md
   â†’ Complete checklist of all changes
   â†’ Decision tree for outcomes
   â†’ Validation before running

3. /code/analysis/labeling_strategy_recommendations.md
   â†’ Full strategy hierarchy (3 strategies)
   â†’ Phase 1, Phase 2, Phase 3 plans
   â†’ Academic justification and references

4. /code/IMPLEMENTATION_SUMMARY.txt (this file)
   â†’ Quick visual reference
   â†’ At-a-glance overview

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
 KEY METRICS TO TRACK
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Accuracy (overall):
  Baseline:  35.56%
  Target:    45-50%
  Check:     Did it improve?

Class Predictions (should become more balanced):
  Baseline - Down:    22.4% (vs actual 31.65%)
  Baseline - Neutral: 38.8% (vs actual 33.57%)
  Baseline - Up:      38.8% (vs actual 35.01%)
  
  Target - Down:     â‰ˆ 30-35%
  Target - Neutral:  â‰ˆ 30-35%
  Target - Up:       â‰ˆ 30-35%

Model Confidence:
  Baseline:  0.41 avg probability
  Target:    > 0.45 avg probability

Training Stability:
  Watch for: Smooth loss convergence (Focal Loss should be more stable)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
 NEXT STEPS AFTER PHASE 1
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âœ… If accuracy > 42%:
   â†’ Phase 1 validated! Class imbalance was the bottleneck
   â†’ PROCEED TO PHASE 2: Multi-Task Learning
   â†’ Expected Phase 2 accuracy: 70-75%

âš ï¸ If accuracy < 38%:
   â†’ Class imbalance is NOT the main issue
   â†’ STOP and investigate:
     â€¢ Feature quality/engineering
     â€¢ Temporal window size
     â€¢ Graph structure design
     â€¢ Model architecture limitations

ğŸŸ¡ If accuracy 38-42%:
   â†’ Partial improvement, class imbalance is A factor but not THE factor
   â†’ Continue to Phase 2 with caution
   â†’ Investigate other bottlenecks in parallel

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
 ACADEMIC FOUNDATION
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Paper:     Lin et al., "Focal Loss for Dense Object Detection" (2017)
Journal:   ICCV 2017
Citation:  https://arxiv.org/abs/1708.02002
Original Application: Object detection with extreme class imbalance

Financial ML Reference:
  LÃ³pez de Prado, "Advances in Financial Machine Learning" (2018)
  - Chapter 3: Labeling (discusses why 3-class is hard with noisy data)
  - Chapter 8: Meta-Labeling (discusses binary filtering approach)

Why it works:
  â€¢ Addresses class imbalance mathematically
  â€¢ Proven in computer vision (RetinaNet won competitions)
  â€¢ Applicable to finance (class imbalance common in market data)
  â€¢ Simpler than oversampling or SMOTE

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
 SAFETY & REVERSIBILITY
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âœ… Non-breaking changes:
   - Only loss function modified
   - No model architecture changes
   - No data loading changes
   - No evaluation changes

âœ… Reversible:
   - Can revert to CrossEntropyLoss in 1 line
   - All original code still there
   - FocalLoss class doesn't affect anything else

âœ… Isolated:
   - Doesn't affect other experiments
   - Doesn't affect other models
   - Doesn't affect data pipeline

âœ… Low risk:
   - Pure mathematical change to loss function
   - No new dependencies
   - Tested academic technique

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
 SUMMARY
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Status: âœ… READY TO RUN

Phase 1 Implementation is COMPLETE:
  â€¢ FocalLoss class added to train.py
  â€¢ Notebook modified to use FocalLoss
  â€¢ Comprehensive documentation created
  â€¢ All changes are safe and reversible

Next Action: Run the notebook and monitor accuracy improvement

Decision Point: If accuracy > 42%, proceed to Phase 2 âœ…

Time to Complete: ~1-2 hours on GPU

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘              Ready to validate class imbalance hypothesis!                 â•‘
â•‘                                                                            â•‘
â•‘  Run Phase 1 â†’ Get accuracy signal â†’ Decide on Phase 2 or pivot           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
